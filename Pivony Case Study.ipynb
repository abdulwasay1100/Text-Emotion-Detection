{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Text Detection Using Emotion Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link to the Dataset: https://github.com/Jcharis/end2end-nlp-project/blob/main/notebooks/data/emotion_dataset_raw.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we will Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ml pckg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    " Then we will analyze our dataset and look for missing values. Then we will clean the dataset so that it will be able to be used in the Machine Learning Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('archive/emotion_dataset_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34792 entries, 0 to 34791\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Emotion     34792 non-null  object\n",
      " 1   Text        34792 non-null  object\n",
      " 2   Clean_text  34792 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 815.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion    0\n",
       "Text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         11045\n",
       "sadness      6722\n",
       "fear         5410\n",
       "anger        4297\n",
       "surprise     4062\n",
       "neutral      2254\n",
       "disgust       856\n",
       "shame         146\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neattext.functions as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTC_ADDRESS_REGEX',\n",
       " 'CURRENCY_REGEX',\n",
       " 'CURRENCY_SYMB_REGEX',\n",
       " 'Counter',\n",
       " 'DATE_REGEX',\n",
       " 'EMAIL_REGEX',\n",
       " 'EMOJI_REGEX',\n",
       " 'HASTAG_REGEX',\n",
       " 'MASTERCard_REGEX',\n",
       " 'MD5_SHA_REGEX',\n",
       " 'MOST_COMMON_PUNCT_REGEX',\n",
       " 'NUMBERS_REGEX',\n",
       " 'PHONE_REGEX',\n",
       " 'PoBOX_REGEX',\n",
       " 'SPECIAL_CHARACTERS_REGEX',\n",
       " 'STOPWORDS',\n",
       " 'STOPWORDS_de',\n",
       " 'STOPWORDS_en',\n",
       " 'STOPWORDS_es',\n",
       " 'STOPWORDS_fr',\n",
       " 'STOPWORDS_ru',\n",
       " 'STOPWORDS_yo',\n",
       " 'STREET_ADDRESS_REGEX',\n",
       " 'TextFrame',\n",
       " 'URL_PATTERN',\n",
       " 'USER_HANDLES_REGEX',\n",
       " 'VISACard_REGEX',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__generate_text',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__numbers_dict',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_lex_richness_herdan',\n",
       " '_lex_richness_maas_ttr',\n",
       " 'clean_text',\n",
       " 'defaultdict',\n",
       " 'digit2words',\n",
       " 'extract_btc_address',\n",
       " 'extract_currencies',\n",
       " 'extract_currency_symbols',\n",
       " 'extract_dates',\n",
       " 'extract_emails',\n",
       " 'extract_emojis',\n",
       " 'extract_hashtags',\n",
       " 'extract_html_tags',\n",
       " 'extract_mastercard_addr',\n",
       " 'extract_md5sha',\n",
       " 'extract_numbers',\n",
       " 'extract_pattern',\n",
       " 'extract_phone_numbers',\n",
       " 'extract_postoffice_box',\n",
       " 'extract_shortwords',\n",
       " 'extract_special_characters',\n",
       " 'extract_stopwords',\n",
       " 'extract_street_address',\n",
       " 'extract_terms_in_bracket',\n",
       " 'extract_urls',\n",
       " 'extract_userhandles',\n",
       " 'extract_visacard_addr',\n",
       " 'fix_contractions',\n",
       " 'generate_sentence',\n",
       " 'hamming_distance',\n",
       " 'inverse_df',\n",
       " 'lexical_richness',\n",
       " 'markov_chain',\n",
       " 'math',\n",
       " 'nlargest',\n",
       " 'normalize',\n",
       " 'num2words',\n",
       " 'random',\n",
       " 're',\n",
       " 'read_txt',\n",
       " 'remove_bad_quotes',\n",
       " 'remove_btc_address',\n",
       " 'remove_currencies',\n",
       " 'remove_currency_symbols',\n",
       " 'remove_custom_pattern',\n",
       " 'remove_custom_words',\n",
       " 'remove_dates',\n",
       " 'remove_emails',\n",
       " 'remove_emojis',\n",
       " 'remove_hashtags',\n",
       " 'remove_html_tags',\n",
       " 'remove_mastercard_addr',\n",
       " 'remove_md5sha',\n",
       " 'remove_multiple_spaces',\n",
       " 'remove_non_ascii',\n",
       " 'remove_numbers',\n",
       " 'remove_phone_numbers',\n",
       " 'remove_postoffice_box',\n",
       " 'remove_puncts',\n",
       " 'remove_punctuations',\n",
       " 'remove_shortwords',\n",
       " 'remove_special_characters',\n",
       " 'remove_stopwords',\n",
       " 'remove_street_address',\n",
       " 'remove_terms_in_bracket',\n",
       " 'remove_urls',\n",
       " 'remove_userhandles',\n",
       " 'remove_visacard_addr',\n",
       " 'replace_bad_quotes',\n",
       " 'replace_currencies',\n",
       " 'replace_currency_symbols',\n",
       " 'replace_dates',\n",
       " 'replace_emails',\n",
       " 'replace_emojis',\n",
       " 'replace_numbers',\n",
       " 'replace_phone_numbers',\n",
       " 'replace_special_characters',\n",
       " 'replace_term',\n",
       " 'replace_urls',\n",
       " 'string',\n",
       " 'term_freq',\n",
       " 'to_txt',\n",
       " 'word_freq',\n",
       " 'word_length_freq']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_text']=df['Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_text']=df['Clean_text'].apply(nfx.remove_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_text']=df['Clean_text'].apply(nfx.remove_non_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_text']=df['Clean_text'].apply(nfx.remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_text']=df['Clean_text'].apply(nfx.remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_text']=df['Clean_text'].apply(nfx.remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_text']=df['Clean_text'].apply(nfx.remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>Why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL MAN I H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>Such an eye  The true hazel eyeand so brillia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>ugh babe hugggzzz for u   babe naamazed nga ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text  \\\n",
       "0  neutral                                             Why ?    \n",
       "1      joy    Sage Act upgrade on my to do list for tommorow.   \n",
       "2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3      joy   Such an eye ! The true hazel eye-and so brill...   \n",
       "4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "\n",
       "                                          Clean_text  \n",
       "0                                              Why    \n",
       "1     Sage Act upgrade on my to do list for tommorow  \n",
       "2  ON THE WAY TO MY HOMEGIRL BABY FUNERAL MAN I H...  \n",
       "3   Such an eye  The true hazel eyeand so brillia...  \n",
       "4    ugh babe hugggzzz for u   babe naamazed nga ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL MAN I H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye  The true hazel eyeand so brillia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>ugh babe hugggzzz for u   babe naamazed nga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>surprise</td>\n",
       "      <td>have you gift Hope you like it Its hand made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to meso the world MOST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34790</th>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY I call it of   YOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby and I dream about you a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                         Clean_text\n",
       "0       neutral                                              Why  \n",
       "1           joy     Sage Act upgrade on my to do list for tommorow\n",
       "2       sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL MAN I H...\n",
       "3           joy   Such an eye  The true hazel eyeand so brillia...\n",
       "4           joy    ugh babe hugggzzz for u   babe naamazed nga ...\n",
       "...         ...                                                ...\n",
       "34787  surprise    have you gift Hope you like it Its hand made...\n",
       "34788       joy  The world didnt give it to meso the world MOST...\n",
       "34789     anger                            A man robbed me today  \n",
       "34790      fear           Youu call it JEALOUSY I call it of   YOU\n",
       "34791   sadness  I think about you baby and I dream about you a...\n",
       "\n",
       "[34792 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Text', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Features and Labels for the Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will check different Machine learning models and there accuracy then will choose the model with the most accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df['Clean_text']\n",
    "labels=df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(x, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv_model=MultinomialNB()\n",
    "nv_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5602605863192183"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fear', 'sadness', 'sadness', ..., 'sadness', 'joy', 'sadness'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=['You guys are nuts WHY ARE YOU GOING THERE WHEN YOU KNOW ITS RISKY']\n",
    "sample_cv=cv.transform(sample).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fear'], dtype='<U8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv_model.predict(sample_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg=LogisticRegression(random_state=0, solver='liblinear')\n",
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6313470013412531"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.predict(sample_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier= tree.DecisionTreeClassifier(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5201187967043495"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(sample_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_classifier=RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "RF_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_detection(data, model):\n",
    "    vec=cv.transform(data).toarray()\n",
    "    prediction=model.predict(vec)\n",
    "    prob_pred=model.predict_proba(vec)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is ['neutral'], with probability 0.4799192636466322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'anger': 0.036011441772148406,\n",
       " 'disgust': 0.04082495069407158,\n",
       " 'fear': 0.14599408864597282,\n",
       " 'joy': 0.01312176848648796,\n",
       " 'neutral': 0.4799192636466322,\n",
       " 'sadness': 0.051507894813119716,\n",
       " 'shame': 0.0003268747682437447,\n",
       " 'surprise': 0.23229371717332353}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_detection(sample, lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using our Model to predict the text on the data of Climate-pp.csv and meta_nc.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('archive/climate-pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocText</th>\n",
       "      <th>DocDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400 private jets too the climate change summit...</td>\n",
       "      <td>2021-11-02 23:23:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Covid” restrictions are so much like “Climate...</td>\n",
       "      <td>2021-11-02 23:22:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you to everybody who made this a success...</td>\n",
       "      <td>2021-11-02 23:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anti-climate change **** deserve love and respect</td>\n",
       "      <td>2021-11-02 22:27:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very alarming ang effects ng climate change es...</td>\n",
       "      <td>2021-11-02 22:26:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Always love @amelia_draper on @nbcwashington p...</td>\n",
       "      <td>2021-03-16 22:42:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Thank you @NYSenDems for including the $3 bill...</td>\n",
       "      <td>2021-03-16 22:20:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Thank you so much @Kevin_Fong @astro_timpeake,...</td>\n",
       "      <td>2021-03-16 20:55:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Always love seeing representatives of actual p...</td>\n",
       "      <td>2021-03-15 23:46:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Amazing that you can tell with great accuracy ...</td>\n",
       "      <td>2021-03-14 23:31:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               DocText              DocDate\n",
       "0    400 private jets too the climate change summit...  2021-11-02 23:23:58\n",
       "1    “Covid” restrictions are so much like “Climate...  2021-11-02 23:22:22\n",
       "2    Thank you to everybody who made this a success...  2021-11-02 23:09:11\n",
       "3    anti-climate change **** deserve love and respect  2021-11-02 22:27:22\n",
       "4    Very alarming ang effects ng climate change es...  2021-11-02 22:26:23\n",
       "..                                                 ...                  ...\n",
       "361  Always love @amelia_draper on @nbcwashington p...  2021-03-16 22:42:09\n",
       "362  Thank you @NYSenDems for including the $3 bill...  2021-03-16 22:20:31\n",
       "363  Thank you so much @Kevin_Fong @astro_timpeake,...  2021-03-16 20:55:31\n",
       "364  Always love seeing representatives of actual p...  2021-03-15 23:46:38\n",
       "365  Amazing that you can tell with great accuracy ...  2021-03-14 23:31:41\n",
       "\n",
       "[366 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test_df['DocText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Prediction']=emotion_detection(test, lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocText</th>\n",
       "      <th>DocDate</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400 private jets too the climate change summit...</td>\n",
       "      <td>2021-11-02 23:23:58</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Covid” restrictions are so much like “Climate...</td>\n",
       "      <td>2021-11-02 23:22:22</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you to everybody who made this a success...</td>\n",
       "      <td>2021-11-02 23:09:11</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anti-climate change **** deserve love and respect</td>\n",
       "      <td>2021-11-02 22:27:22</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very alarming ang effects ng climate change es...</td>\n",
       "      <td>2021-11-02 22:26:23</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Always love @amelia_draper on @nbcwashington p...</td>\n",
       "      <td>2021-03-16 22:42:09</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Thank you @NYSenDems for including the $3 bill...</td>\n",
       "      <td>2021-03-16 22:20:31</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Thank you so much @Kevin_Fong @astro_timpeake,...</td>\n",
       "      <td>2021-03-16 20:55:31</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Always love seeing representatives of actual p...</td>\n",
       "      <td>2021-03-15 23:46:38</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Amazing that you can tell with great accuracy ...</td>\n",
       "      <td>2021-03-14 23:31:41</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               DocText              DocDate  \\\n",
       "0    400 private jets too the climate change summit...  2021-11-02 23:23:58   \n",
       "1    “Covid” restrictions are so much like “Climate...  2021-11-02 23:22:22   \n",
       "2    Thank you to everybody who made this a success...  2021-11-02 23:09:11   \n",
       "3    anti-climate change **** deserve love and respect  2021-11-02 22:27:22   \n",
       "4    Very alarming ang effects ng climate change es...  2021-11-02 22:26:23   \n",
       "..                                                 ...                  ...   \n",
       "361  Always love @amelia_draper on @nbcwashington p...  2021-03-16 22:42:09   \n",
       "362  Thank you @NYSenDems for including the $3 bill...  2021-03-16 22:20:31   \n",
       "363  Thank you so much @Kevin_Fong @astro_timpeake,...  2021-03-16 20:55:31   \n",
       "364  Always love seeing representatives of actual p...  2021-03-15 23:46:38   \n",
       "365  Amazing that you can tell with great accuracy ...  2021-03-14 23:31:41   \n",
       "\n",
       "    Prediction  \n",
       "0         fear  \n",
       "1      sadness  \n",
       "2          joy  \n",
       "3          joy  \n",
       "4          joy  \n",
       "..         ...  \n",
       "361        joy  \n",
       "362        joy  \n",
       "363   surprise  \n",
       "364        joy  \n",
       "365       fear  \n",
       "\n",
       "[366 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test=pd.read_csv('archive/meta_nc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocText</th>\n",
       "      <th>DocDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook doesn’t have a great rep when it come...</td>\n",
       "      <td>2021-10-28 23:59:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wasn’t Meta a superhero in one of the Pixar mo...</td>\n",
       "      <td>2021-10-28 23:59:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not that it will lead anywhere but the idea be...</td>\n",
       "      <td>2021-10-28 23:59:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zuckerburg changing FB to Meta just confirms w...</td>\n",
       "      <td>2021-10-28 23:59:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everytime i open twitter now i see a headline ...</td>\n",
       "      <td>2021-10-28 23:58:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>bad team? oh no its just anti meta you wouldnt...</td>\n",
       "      <td>2021-10-27 00:46:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>no one is a must pull in this game not zhongli...</td>\n",
       "      <td>2021-10-27 00:29:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>Isn't drawing a tree on paper actually meta ?</td>\n",
       "      <td>2021-10-27 00:20:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>\"isn't that awesome\" -dad's gf referring to ho...</td>\n",
       "      <td>2021-10-27 00:07:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>I think the meta verse is dumb.</td>\n",
       "      <td>2021-10-27 00:06:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2647 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                DocText              DocDate\n",
       "0     Facebook doesn’t have a great rep when it come...  2021-10-28 23:59:52\n",
       "1     Wasn’t Meta a superhero in one of the Pixar mo...  2021-10-28 23:59:51\n",
       "2     Not that it will lead anywhere but the idea be...  2021-10-28 23:59:27\n",
       "3     Zuckerburg changing FB to Meta just confirms w...  2021-10-28 23:59:23\n",
       "4     Everytime i open twitter now i see a headline ...  2021-10-28 23:58:55\n",
       "...                                                 ...                  ...\n",
       "2642  bad team? oh no its just anti meta you wouldnt...  2021-10-27 00:46:13\n",
       "2643  no one is a must pull in this game not zhongli...  2021-10-27 00:29:15\n",
       "2644      Isn't drawing a tree on paper actually meta ?  2021-10-27 00:20:24\n",
       "2645  \"isn't that awesome\" -dad's gf referring to ho...  2021-10-27 00:07:42\n",
       "2646                    I think the meta verse is dumb.  2021-10-27 00:06:51\n",
       "\n",
       "[2647 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_text=meta_test['DocText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test['Predictions']=emotion_detection(meta_text, lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocText</th>\n",
       "      <th>DocDate</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook doesn’t have a great rep when it come...</td>\n",
       "      <td>2021-10-28 23:59:52</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wasn’t Meta a superhero in one of the Pixar mo...</td>\n",
       "      <td>2021-10-28 23:59:51</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not that it will lead anywhere but the idea be...</td>\n",
       "      <td>2021-10-28 23:59:27</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zuckerburg changing FB to Meta just confirms w...</td>\n",
       "      <td>2021-10-28 23:59:23</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everytime i open twitter now i see a headline ...</td>\n",
       "      <td>2021-10-28 23:58:55</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>bad team? oh no its just anti meta you wouldnt...</td>\n",
       "      <td>2021-10-27 00:46:13</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>no one is a must pull in this game not zhongli...</td>\n",
       "      <td>2021-10-27 00:29:15</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>Isn't drawing a tree on paper actually meta ?</td>\n",
       "      <td>2021-10-27 00:20:24</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>\"isn't that awesome\" -dad's gf referring to ho...</td>\n",
       "      <td>2021-10-27 00:07:42</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>I think the meta verse is dumb.</td>\n",
       "      <td>2021-10-27 00:06:51</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                DocText              DocDate  \\\n",
       "0     Facebook doesn’t have a great rep when it come...  2021-10-28 23:59:52   \n",
       "1     Wasn’t Meta a superhero in one of the Pixar mo...  2021-10-28 23:59:51   \n",
       "2     Not that it will lead anywhere but the idea be...  2021-10-28 23:59:27   \n",
       "3     Zuckerburg changing FB to Meta just confirms w...  2021-10-28 23:59:23   \n",
       "4     Everytime i open twitter now i see a headline ...  2021-10-28 23:58:55   \n",
       "...                                                 ...                  ...   \n",
       "2642  bad team? oh no its just anti meta you wouldnt...  2021-10-27 00:46:13   \n",
       "2643  no one is a must pull in this game not zhongli...  2021-10-27 00:29:15   \n",
       "2644      Isn't drawing a tree on paper actually meta ?  2021-10-27 00:20:24   \n",
       "2645  \"isn't that awesome\" -dad's gf referring to ho...  2021-10-27 00:07:42   \n",
       "2646                    I think the meta verse is dumb.  2021-10-27 00:06:51   \n",
       "\n",
       "     Predictions  \n",
       "0            joy  \n",
       "1        neutral  \n",
       "2          anger  \n",
       "3       surprise  \n",
       "4            joy  \n",
       "...          ...  \n",
       "2642     sadness  \n",
       "2643       anger  \n",
       "2644    surprise  \n",
       "2645     disgust  \n",
       "2646     neutral  \n",
       "\n",
       "[2647 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
